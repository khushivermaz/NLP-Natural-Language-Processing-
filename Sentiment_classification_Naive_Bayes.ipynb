{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will perform Sentiment Analysis using Naive Bayes Classifier. We are going to implement different technique like Segmentation, Stopwords, Bag of words model.\n",
    "\n",
    "* Let’s begin!\n",
    "\n",
    "* We will import necessary libraries then read the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "df = pd.read_csv(\"D:/NLP/INT344/archive/IMDB_Dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let’s check the size of dataset.\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are 50000 samples(rows). The data is huge. Let’s take a sample for now. This will make our job easy and quicker.\n",
    "# Subset\n",
    "df = df.sample(1000)\n",
    "# resetting index\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "# sample dataset size\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>First off, this movie leaves you in a limbo mo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Undoubtedly, the least among the Spaghetti Wes...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This screened at Sundance last night to a rece...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I just finished this movie and my only comment...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I really wanted to like this movie. I absolute...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  First off, this movie leaves you in a limbo mo...          0\n",
       "1  Undoubtedly, the least among the Spaghetti Wes...          0\n",
       "2  This screened at Sundance last night to a rece...          0\n",
       "3  I just finished this movie and my only comment...          1\n",
       "4  I really wanted to like this movie. I absolute...          0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let’s update target variables as binary values 0 and 1\n",
    "# positive:1 , negative:0\n",
    "df['sentiment'].replace({'positive':1, 'negative':0}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "Data preprocessing is important stage in classification.\n",
    "\n",
    "We will remove the noise from the dataset such as html tags, brackets, special characters. Let’s change everything to lower case (abcd)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to remove noise\n",
    "# remove html tags\n",
    "def clean_html(text):\n",
    " clean = re.compile('<.*?>')\n",
    " return re.sub(clean, '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove brackets\n",
    "def remove_brackets(text):\n",
    " return re.sub('\\[[^]]*\\]', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower the cases\n",
    "def lower_cases(text):\n",
    " return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove special characters\n",
    "def remove_char(text):\n",
    " pattern = r'[^a-zA-z0–9\\s]'\n",
    " text = re.sub(pattern, '', text)\n",
    " return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove noise(combine above functions)\n",
    "def remove_noise(text):\n",
    " text = clean_html(text)\n",
    " text = remove_brackets(text)\n",
    " text = lower_cases(text) \n",
    " text = remove_char(text) \n",
    " return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      first off this movie leaves you in a limbo moo...\n",
       "1      undoubtedly the least among the spaghetti west...\n",
       "2      this screened at sundance last night to a rece...\n",
       "3      i just finished this movie and my only comment...\n",
       "4      i really wanted to like this movie i absolutel...\n",
       "                             ...                        \n",
       "995    in a nutshell skip this movie its that bad in ...\n",
       "996    i found the movie at my local video store and ...\n",
       "997    some major spoilers youve been warnedi saw thi...\n",
       "998    an old intellectual talks about what he consid...\n",
       "999    to be brutally honest i loved watching severed...\n",
       "Name: review, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call the function on predictors\n",
    "df['review']=df['review'].apply(remove_noise)\n",
    "df['review']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to use Stemming, a text normalization technique in Natural Language Processing (NLP). This technique will reduce the word size ( for example “calling” and “called” words will be reduced to “call”. So we will have 3 words as “call”)\n",
    "\n",
    "Stemming is the process of reducing a word to its word stem that affixes to suffixes and prefixes or to the roots of words known as a lemma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "def stem_words(text):\n",
    " ps = PorterStemmer()\n",
    " stem_list = [ps.stem(word) for word in text.split()] \n",
    " text = ''.join(ps.stem(word) for word in text)\n",
    "\n",
    " return text\n",
    "df['review'] = df['review'].apply(stem_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s remove Stopwords. These words do not add much meaning to a sentence. They can safely be ignored without sacrificing the meaning of the sentence in the reviews. “the, is, at, which, and on” are few common stop words we see in English.\n",
    "\n",
    "Stop words are the words in a stop list (or stoplist or negative dictionary) which are filtered out (i.e. stopped) before or after processing of natural language data (text) because they are insignificant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing from nlptoolkit library\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating list of english stopwords\n",
    "stopword_list = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [movies, one, redeemable, quality, besides, at...\n",
       "1      [know, guts, beauty, guts, virgin, crap, films...\n",
       "2      [film, two, characters, takes, closer, two, pe...\n",
       "3      [gundam009, became, movie, trilogy, us, famili...\n",
       "4      [bad, acting, bad, writing, poorly, written, f...\n",
       "                             ...                        \n",
       "995    [ok, gave, obviously, money, make, film, feel,...\n",
       "996    [mistakenly, kept, awake, late, last, night, w...\n",
       "997    [first, two, jim, thompson, adaptations, relea...\n",
       "998    [confess, know, involved, forerunner, planet, ...\n",
       "999    [despite, overall, pleasing, plot, expensive, ...\n",
       "Name: review, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing the stopwords from review\n",
    "def remove_stopwords(text):\n",
    "    # list to add filtered words from review\n",
    "    filtered_text = []\n",
    "    # verify & append words from the text to filtered_text list\n",
    "    for word in text.split():\n",
    "        if word not in stopword_list:\n",
    "            filtered_text.append(word)\n",
    "    # add content from filtered_text list to new variable\n",
    "    clean_review = filtered_text[:]\n",
    "    # emptying the filtered_text list for new review\n",
    "    filtered_text.clear()\n",
    "    return clean_review\n",
    "df['review']=df['review'].apply(remove_stopwords)\n",
    "df['review']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join back all words as single paragraph\n",
    "def join_back(text):\n",
    "    return ' '.join(text)\n",
    "df['review'] = df['review'].apply(join_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>movies one redeemable quality besides ators ba...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>know guts beauty guts virgin crap films hated ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>film two characters takes closer two people in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gundam009 became movie trilogy us familiar lot...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bad acting bad writing poorly written film bad...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  movies one redeemable quality besides ators ba...          0\n",
       "1  know guts beauty guts virgin crap films hated ...          1\n",
       "2  film two characters takes closer two people in...          1\n",
       "3  gundam009 became movie trilogy us familiar lot...          1\n",
       "4  bad acting bad writing poorly written film bad...          0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if changes are applied\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to perform feature extraction on reviews column to into numerical feature vector. Feature extraction is most important sub-tasks in pattern classification. It yields better results than applying machine learning directly to the raw data.\n",
    "\n",
    "Feature extracion refers to the process of transforming raw data into numerical features that can be processed while preserving the information in the original data set.\n",
    "\n",
    "We will use Bag of Words Vectorization technique for conversion. This is a classic approach of converting input data from its raw format (i.e. text ) into vectors of real numbers which is the format that ML models support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let’s begin converting out input text data.\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features=800)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorizing words and storing in variable X(predictor)\n",
    "X = cv.fit_transform(df['review']).toarray()\n",
    "# predictor\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 800)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X size\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target\n",
    "y = df.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y size\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will get an array of 0 and 1 as input feature X. And columns have increased from 1 to 800, number of rows(samples) are 1000.\n",
    "Now we will split the data into test and train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally, let’s fit the Naive Bayes Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes Classifiers\n",
    "gnb = GaussianNB()\n",
    "mnb = MultinomialNB()\n",
    "bnb = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting and predicting\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred_gnb = gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb.fit(X_train, y_train)\n",
    "y_pred_mnb = mnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb.fit(X_train, y_train)\n",
    "y_pred_bnb = bnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian 0.745\n",
      "Multinomial 0.85\n",
      "Bernoulli 0.855\n"
     ]
    }
   ],
   "source": [
    "# accuracy scores\n",
    "print(\"Gaussian\", accuracy_score(y_test, y_pred_gnb))\n",
    "print(\"Multinomial\", accuracy_score(y_test, y_pred_mnb))\n",
    "print(\"Bernoulli\", accuracy_score(y_test, y_pred_bnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openvino_env",
   "language": "python",
   "name": "openvino_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
